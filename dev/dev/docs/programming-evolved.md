# Programming, Evolved: Lessons & Observations

Drafted on December 2025 (v1), January 2026 (v2)

**TL;DR: If you are a software engineer, regardless of the level, pick a model, any model, and shape it to be your best pair programming buddy.** This sentiment generalizes beyond software engineers.

I have been using Copilot, Cody, and Cursor for about a year and a half. I started using Claude Code, Codex, and Gemini since their release [earlier this year](https://github.com/kulesh/dotfiles/tree/main/dev/dev/ai-kata). Using these tools I wrote code and debugged problems with teams. I am also writing more code for myself, friends, and family. This is a quick write-up of lessons and observations from the past ~18 months.

Let me first define some terms. I like [Titus Winter's definition of Software Engineering](https://www.youtube.com/watch?t=472&v=tISy7EJQPzI&feature=youtu.be&themeRefresh=1). Software Engineering is a function of programming, people, and time. Programming is the pursuit of one person to solve a problem they know using code. When you add time, teams, and trade-offs to programming it is software engineering. Software Engineering is a team sport. Software Engineering has always been about collaborating with people to learn and understand a problem, writing code to solve the problem, finding and fixing bugs, and evolving the solution over time as the problem evolves.

Programming has gone through many evolutions in the past. Languages evolved from machine code, low-level languages, high-level languages, to object oriented and functional languages. Programming environments also evolved from punch cards, line editors, screen editors, to integrated development environments. Each step in the evolution stripped away distractions and refined programming of its essence: organization of logic. This refinement helped bring more programmers into the field and they solved more problems than previous generations.

It is happening again and it is happening more broadly and quickly than previous evolutions[^1]. We are in the midst of the Cambrian Explosion of programming.

## Lessons & Observations

1. These tools obviously improved significantly over the past 12 months. I would say they improved in three dimensions:
   - The backing models generate better quality code for languages in their distribution (i.e. Python, TypeScript, Rust, Go, etc.)
   - Thanks to innovations in harness built around the models, coding assistants can work on problems longer and reliably produce coherent output.
   - The coding assistants generate code more grounded in the codebase they are working on as opposed to the codebases they have been trained on.
2. Coding assistants are very good at solving known problems. You are not going to make them _consistently_ one-shot a well-optimized renderer or an RL algorithm _but_ they can write run-of-the-mill business logic better _and_ faster than I can. When I optimize for both speed of production _and_ quality, they win!
3. There is room for improvement in their ability to generate functioning frontends and good quality frontend code. Based on my experiences using coding agents for developing [web UIs](https://github.com/kulesh/catsyphon) and [TUIs](https://github.com/kulesh/aiobscura), I can say they struggle to generate good looking, well-functioning user interfaces backed by idiomatic code. Current models are bad at Tailwind, bad at Ink, bad at Textual, and OK at Ratatui. Unclear whether it is a sampling problem or the heavy abstractions in the UI frameworks are tripping them up--those abstractions certainly trip me up. For web and mobile UIs I use [Google Stitch](https://stitch.withgoogle.com/); Stitch cannot produce mocks for TUIs yet.
4. Their personality is to just solve the problem in front of them as quickly as possible and get your praise. This tendency leads them to make sub-optimal decisions. For example, I have caught Opus 4.5 trying to solve a deadlock by letting a process "sleep for 2 seconds." This personality can be altered with appropriate guidance. For example, a shortcut I lean on is to use the word "_idiomatic_" in my prompts--"_come up with an idiomatic solution_" or "_is that the most idiomatic way of solving the problem?_" Similarly, when writing tests or reviewing tests I pepper "_intent of the function under test_" here and there which makes the model output better tests. If you look at [Claude Code's harness](https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents) they [use a similar tricks](https://medium.com/@outsightai/peeking-under-the-hood-of-claude-code-70f5a94a9a62) to keep the model on the rails.
5. These models, esp. Opus 4.5 and GPT 5.2, are remarkable bug hunters. I can point at a symptom and they can read the code, and they come away with the bug. I then ask them to [explain to me why the bug happens](https://x.com/kulesh/status/1996764098357276858) and follow the code to see if the explanation is correct. I have not come across a bad bug yet. They can find deadlocks and starvation, you then have to guide them to a good fix (see above). Sometimes, if I know a particular component has a bug I ask them to first create a mental model for themselves and then they can find some gnarly bugs. [Jan 2026 Update] This doesn't always work though. One of the bugs both of these models fail to pick up is [this memory leak in Ghostty](https://mitchellh.com/writing/ghostty-memory-leak-fix). I am still trying to scaffold their mental model to see if they can pick up the bug from a commit prior to the fix.
6. Code quality is not sufficient to create product quality. However, it is a necessary ingredient to sustain product quality. My experience is, even with the best scaffolding the half-life of product quality is shorter for primarily coding agent generated codebases. As you pick up coding assistants be sure to also create [robust skills](https://github.com/kulesh/dotfiles/blob/main/claude/.claude/commands/review-changes.md?plain=1) around the assistant to improve code quality. A study of code quality of open source coding assistants would be revealing.
7. Much like journaling, the process of writing software actually gives you a good mental model of what's being built. I find this mental model useful in two scenarios: when making decisions during the evolution of the software and when debugging a problem (esp. during an incident). When coding assistants write most of the software the fidelity of the mental model I hold degrade quickly. Instead of fighting this new normal I have been trying to create methods to use the model as a tool to query and develop the mental model post facto. It's not the same but I think it is going to be the new norm. We need tooling in this space.
8. If you have abstained from incorporating coding assistants thus far, perhaps the best way to get them incorporated is by starting to use them for attending to your toil. They are good at comprehending stack traces, poorly written code, summarizing documentation, querying documentation for specifics, etc.
9. Over the years I must have spent hundreds of hours fine tuning my editor to make it feel just right. I am using that editor to write this document, and it is my editor. I don't spend as much time as I used to in the editor anymore. Now I am the “editor” to my coding assistant (Claude Code, Codex, and OpenCode). I am spending as much time learning about them as I am spending time teaching them new tricks, skills, and commands. I built [Catsyphon](https://github.com/kulesh/catsyphon) and [Aiobscura](https://github.com/kulesh/aiobscura) just so I can review and learn from our interactions. A lot of the lessons in this list come from such reviews. I look at this as an opportunity to grow and mentor my pair programming buddy.
10. Coding Assistants come with a sandbox. However, the sandbox tends to get in the way of the coding agents that make up the assistants. So I rely on an exo-sandbox– a sandbox outside of coding assistants. I am now [using sandbox-exec to guard my sessions](https://github.com/kulesh/dotfiles/pull/8/files) and turned off sandboxes in the coding agents. Not recommending for everyone but just know you have choices.
11. There is so much fun, beauty and pleasure in writing code by hand. You can still handcraft code. Don't expect this to be your job. This is your passion.

[^1]: I think it is happening faster than ever because distribution channels are mature, most layers are software, and network of people is large and dense.
